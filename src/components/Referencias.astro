---
import Slide from "./Slide.astro";
---

<>
  <Slide id="referencias" title="6. Referencias">
    <div class="prose prose-invert max-w-none">
      <div class="card references-card">
        <ul class="space-y-4 list-disc pl-5">
          <li>
            <p>
              Blumstein, D. T., Mennill, D. J., Clemins, P., Girod, L., Yao, K., Patricelli, G., Deppe, J. L., Krakauer, A. H., Clark, C., Cortopassi, K. A., Hanser, S. F., McCowan, B., Ali, A. M., & Kirschel, A. N. G. (2011). Acoustic monitoring in terrestrial environments using microphone arrays: applications, technological considerations and prospectus. In Journal of Applied Ecology (Vol. 48, Issue 3, pp. 758–767). Wiley. https://doi.org/10.1111/j.1365-2664.2011.01993.x
            </p>
          </li>
          <li>
            <p>
              Browning, E.; Gibb, R.; Glover-Kapfer, P. and Jones, K.E. (2017) Passive acoustic monitoring in ecology and conservation. Woking, UK, WWF-UK, 76pp. (WWF Conservation Technology Series 1(2)). DOI: http://dx.doi.org/10.25607/OBP-876
            </p>
          </li>
          <li>
            <p>
              Chapman, P., Clinton, J., Kerber, R., Khabaza, T., Reinartz, T., Shearer, C., & Wirth, R. (2000). CRISP-DM 1.0: Step-by-step data mining guide. SPSS Inc.
            </p>
          </li>
          <li>
            <p>
              Choi, K. (s.f.). Kapre: Keras Audio Preprocessors [Software]. GitHub. Recuperado el 16 de mayo de 2025, de https://github.com/keunwoochoi/kapre
            </p>
          </li>
          <li>
            <p>
              Corporation for Digital Scholarship. (s.f.). Zotero [Software]. Recuperado el 16 de mayo de 2025, de https://www.zotero.org/
            </p>
          </li>
          <li>
            <p>
              Gervaise, C., Simard, Y., Aulanier, F., & Roy, N. (2021). Optimizing passive acoustic systems for marine mammal detection and localization: Application to real-time monitoring north Atlantic right whales in Gulf of St. Lawrence. Applied Acoustics, 178, 107949. https://doi.org/10.1016/j.apacoust.2021.107949
            </p>
          </li>
          <li>
            <p>
              Gibb, R., Browning, E., Glover‐Kapfer, P., & Jones, K. E. (2018). Emerging opportunities and challenges for passive acoustics in ecological assessment and monitoring. In L. Börger (Ed.), Methods in Ecology and Evolution (Vol. 10, Issue 2, pp. 169–185). Wiley. https://doi.org/10.1111/2041-210x.13101
            </p>
          </li>
          <li>
            <p>
              Google Research. (s.f.). Colaboratory. Recuperado el 16 de mayo de 2025, de https://colab.research.google.com/
            </p>
          </li>
          <li>
            <p>
              Google. (s.f.). TensorFlow [Software]. Recuperado el 16 de mayo de 2025, de https://www.tensorflow.org/
            </p>
          </li>
          <li>
            <p>
              He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep Residual Learning for Image Recognition. In 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE. https://doi.org/10.1109/cvpr.2016.90
            </p>
          </li>
          <li>
            <p>
              Heinicke, S., Kalan, A. K., Wagner, O. J. J., Mundry, R., Lukashevich, H., & Kühl, H. S. (2015). Assessing the performance of a semi‐automated acoustic monitoring system for primates. In K. Jones (Ed.), Methods in Ecology and Evolution (Vol. 6, Issue 7, pp. 753–763). Wiley. https://doi.org/10.1111/2041-210x.12384
            </p>
          </li>
          <li>
            <p>
              IBM. (s.f.). Ayuda de CRISP-DM: Visión General. IBM SPSS Modeler Documentation. Recuperado el 16 de mayo de 2025, de https://www.ibm.com/docs/es/spss-modeler/saas?topic=dm-crisp-help-overview
            </p>
          </li>
          <li>
            <p>
              K. Lisa Yang Center for Conservation Bioacoustics, Cornell Lab of Ornithology. (s.f.). BirdNet Analyzer. GitHub. Recuperado el 16 de mayo de 2025, de https://github.com/kahst/BirdNET-Analyzer
            </p>
          </li>
          <li>
            <p>
              K. Lisa Yang Center for Conservation Bioacoustics, Cornell Lab of Ornithology. (s.f.). Raven Lite / Raven Pro [Software]. Recuperado el 16 de mayo de 2025, de https://ravensoundsoftware.com/
            </p>
          </li>
          <li>
            <p>
              Kahl, S., Wood, C. M., Eibl, M., & Klinck, H. (2021). BirdNET: A deep learning solution for avian diversity monitoring. In Ecological Informatics (Vol. 61, p. 101236). Elsevier BV. https://doi.org/10.1016/j.ecoinf.2021.101236
            </p>
          </li>
          <li>
            <p>
              Kershenbaum, A., Akçay, Ç., Babu‐Saheer, L., Barnhill, A., Best, P., Cauzinille, J., Clink, D., Dassow, A., Dufourq, E., Growcott, J., Markham, A., Marti‐Domken, B., Marxer, R., Muir, J., Reynolds, S., Root‐Gutteridge, H., Sadhukhan, S., Schindler, L., Smith, B. R., … Dunn, J. C. (2024). Automatic detection for bioacoustic research: a practical guide from and for biologists and computer scientists. Biological Reviews, 100(2), 620–646. https://doi.org/10.1111/brv.13155
            </p>
          </li>
          <li>
            <p>
              Leroy, E. C., Thomisch, K., Royer, J.-Y., Boebel, O., & Van Opzeeland, I. (2018). On the reliability of acoustic annotations and automatic detections of Antarctic blue whale calls under different acoustic conditions. In The Journal of the Acoustical Society of America (Vol. 144, Issue 2, pp. 740–754). Acoustical Society of America (ASA). https://doi.org/10.1121/1.5049803
            </p>
          </li>
          <li>
            <p>
              Librosa development team. (s.f.). librosa [Software]. Recuperado el 16 de mayo de 2025, de https://librosa.org/
            </p>
          </li>
          <li>
            <p>
              Lostanlen, V., Salamon, J., Farnsworth, A., Kelling, S., & Bello, J. P. (2019). Robust sound event detection in bioacoustic sensor networks. In I. McLoughlin (Ed.), PLOS ONE (Vol. 14, Issue 10, p. e0214168). Public Library of Science (PLoS). https://doi.org/10.1371/journal.pone.0214168
            </p>
          </li>
          <li>
            <p>
              McLoughlin, I., Zhang, H., Xie, Z., Song, Y., & Xiao, W. (2015). Robust Sound Event Classification Using Deep Neural Networks. In IEEE/ACM Transactions on Audio, Speech, and Language Processing (Vol. 23, Issue 3, pp. 540–552). IEEE. https://doi.org/10.1109/taslp.2015.2389618
            </p>
          </li>
          <li>
            <p>
              Mesaros, A., Heittola, T., Virtanen, T., & Plumbley, M. D. (2021). Sound Event Detection: A tutorial. In IEEE Signal Processing Magazine (Vol. 38, Issue 5, pp. 67–83). IEEE. https://doi.org/10.1109/msp.2021.3090678
            </p>
          </li>
          <li>
            <p>
              Meta AI. (s.f.). PyTorch [Software]. Recuperado el 16 de mayo de 2025, de https://pytorch.org/
            </p>
          </li>
          <li>
            <p>
              Microsoft. (s.f.). Visual Studio Code [Software]. Recuperado el 16 de mayo de 2025, de https://code.visualstudio.com/
            </p>
          </li>
          <li>
            <p>
              Mutanu, L., Gohil, J., Gupta, K., Wagio, P., & Kotonya, G. (2022). A Review of Automated Bioacoustics and General Acoustics Classification Research. Sensors, 22(21), 8361. https://doi.org/10.3390/s22218361
            </p>
          </li>
          <li>
            <p>
              Nguyen Hong Duc, P., Torterotot, M., Samaran, F., White, P. R., Gérard, O., Adam, O., & Cazau, D. (2021). Assessing inter-annotator agreement from collaborative annotation campaign in marine bioacoustics. In Ecological Informatics (Vol. 61, p. 101185). Elsevier BV. https://doi.org/10.1016/j.ecoinf.2020.101185
            </p>
          </li>
          <li>
            <p>
              Politis, A., Mesaros, A., Adavanne, S., Heittola, T., & Virtanen, T. (2020). Overview and Evaluation of Sound Event Localization and Detection in DCASE 2019. arXiv. https://doi.org/10.48550/ARXIV.2009.02792
            </p>
          </li>
          <li>
            <p>
              Python Software Foundation. (s.f.). Python [Software]. Recuperado el 16 de mayo de 2025, de https://www.python.org/
            </p>
          </li>
          <li>
            <p>
              Rainforest Connection. (s.f.). Arbimon. Recuperado el 16 de mayo de 2025, de https://arbimon.rfcx.org/
            </p>
          </li>
          <li>
            <p>
              Salem, S. I., Shirayama, S., Shimazaki, S., & Oki, K. (2024). Ensemble deep learning and anomaly detection framework for automatic audio classification: Insights into deer vocalizations. Ecological Informatics, 84, 102883. https://doi.org/10.1016/j.ecoinf.2024.102883
            </p>
          </li>
          <li>
            <p>
              Shin, Y., & Chun, C. (2023). Sound Event Localization and Detection Using Imbalanced Real and Synthetic Data via Multi-Generator. In Sensors (Vol. 23, Issue 7, p. 3398). MDPI AG. https://doi.org/10.3390/s23073398
            </p>
          </li>
          <li>
            <p>
              The NumPy Developers. (s.f.). NumPy [Software]. Recuperado el 16 de mayo de 2025, de https://numpy.org/
            </p>
          </li>
          <li>
            <p>
              The Pandas Development Team. (s.f.). pandas - Python Data Analysis Library [Software]. Recuperado el 16 de mayo de 2025, de https://pandas.pydata.org/
            </p>
          </li>
          <li>
            <p>
              Vesely, A. (2008). Problem Tree: A Problem Structuring Heuristic. Central European Journal of Public Policy, 2, 68–81.
            </p>
          </li>
        </ul>
      </div>
    </div>
  </Slide>
</>

<style>
  .card {
    background-color: rgba(17, 24, 39, 0.7);
    border: 1px solid rgba(55, 65, 81, 0.5);
    border-radius: 0.5rem;
    padding: 1rem;
  }
  
  .references-card {
    max-height: 60vh;
    overflow-y: auto;
    scrollbar-width: thin;
    scrollbar-color: rgba(55, 65, 81, 0.5) transparent;
  }

  .references-card::-webkit-scrollbar {
    width: 8px;
  }

  .references-card::-webkit-scrollbar-track {
    background: rgba(17, 24, 39, 0.3);
    border-radius: 4px;
  }

  .references-card::-webkit-scrollbar-thumb {
    background-color: rgba(55, 65, 81, 0.8);
    border-radius: 4px;
  }
</style>
